{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_pred):\n",
    "    return np.sum(y_test == y_pred) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vector(x):\n",
    "    return np.mean(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p1, p2):\n",
    "    p1 = np.array(p1)\n",
    "    p2 = np.array(p2)\n",
    "    return np.sqrt(np.sum((p1 - p2)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"gender.csv\")\n",
    "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data.rename(columns = {'Unnamed: 1': 'class'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.066420</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>-0.066105</td>\n",
       "      <td>-0.041232</td>\n",
       "      <td>-0.002637</td>\n",
       "      <td>-0.158467</td>\n",
       "      <td>0.130467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>-0.046754</td>\n",
       "      <td>-0.118619</td>\n",
       "      <td>-0.163774</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>-0.076400</td>\n",
       "      <td>0.107497</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.030614</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>-0.050324</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>-0.063818</td>\n",
       "      <td>-0.019530</td>\n",
       "      <td>-0.119905</td>\n",
       "      <td>0.186553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>-0.028108</td>\n",
       "      <td>0.040618</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>-0.141244</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.080610</td>\n",
       "      <td>-0.015930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.096178</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>-0.035388</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>-0.018634</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>-0.139786</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111141</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>-0.029222</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>-0.222173</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>0.093428</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.057652</td>\n",
       "      <td>0.086116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.103057</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>-0.035873</td>\n",
       "      <td>-0.028163</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>-0.017016</td>\n",
       "      <td>0.114907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100793</td>\n",
       "      <td>-0.002644</td>\n",
       "      <td>-0.023388</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>-0.015100</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.062462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.125815</td>\n",
       "      <td>0.120046</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>-0.042901</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>-0.049677</td>\n",
       "      <td>-0.054258</td>\n",
       "      <td>-0.130758</td>\n",
       "      <td>0.173457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090197</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>0.039926</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>-0.056852</td>\n",
       "      <td>-0.076700</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.026041</td>\n",
       "      <td>0.084135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.164731</td>\n",
       "      <td>0.064301</td>\n",
       "      <td>0.058630</td>\n",
       "      <td>-0.017420</td>\n",
       "      <td>-0.157600</td>\n",
       "      <td>-0.022536</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.072739</td>\n",
       "      <td>0.030554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095115</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>-0.170753</td>\n",
       "      <td>-0.136630</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.095308</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.092913</td>\n",
       "      <td>-0.101745</td>\n",
       "      <td>-0.083153</td>\n",
       "      <td>-0.028159</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>-0.114513</td>\n",
       "      <td>0.157421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056078</td>\n",
       "      <td>0.119846</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>-0.096594</td>\n",
       "      <td>-0.084553</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>0.030732</td>\n",
       "      <td>-0.083713</td>\n",
       "      <td>0.064970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.202852</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.079731</td>\n",
       "      <td>-0.047156</td>\n",
       "      <td>-0.140062</td>\n",
       "      <td>-0.080246</td>\n",
       "      <td>0.057668</td>\n",
       "      <td>-0.122083</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.035684</td>\n",
       "      <td>-0.023112</td>\n",
       "      <td>-0.030452</td>\n",
       "      <td>-0.154243</td>\n",
       "      <td>-0.188270</td>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>-0.006257</td>\n",
       "      <td>0.039977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.088300</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.049627</td>\n",
       "      <td>-0.026011</td>\n",
       "      <td>-0.172773</td>\n",
       "      <td>0.086218</td>\n",
       "      <td>0.042710</td>\n",
       "      <td>-0.161852</td>\n",
       "      <td>0.185083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039460</td>\n",
       "      <td>0.067547</td>\n",
       "      <td>0.040426</td>\n",
       "      <td>0.028007</td>\n",
       "      <td>-0.154515</td>\n",
       "      <td>-0.127736</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>-0.016942</td>\n",
       "      <td>0.048071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.156201</td>\n",
       "      <td>0.055165</td>\n",
       "      <td>0.142716</td>\n",
       "      <td>-0.115393</td>\n",
       "      <td>-0.128982</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.037305</td>\n",
       "      <td>-0.101402</td>\n",
       "      <td>0.048473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.066980</td>\n",
       "      <td>-0.002332</td>\n",
       "      <td>-0.045738</td>\n",
       "      <td>-0.110557</td>\n",
       "      <td>-0.014995</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>-0.010298</td>\n",
       "      <td>-0.028856</td>\n",
       "      <td>0.075323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class         0         1         2         3         4         5  \\\n",
       "0      male -0.066420  0.151611  0.027740  0.052771 -0.066105 -0.041232   \n",
       "1      male -0.030614  0.049667  0.008084 -0.050324  0.007649 -0.063818   \n",
       "2      male -0.096178  0.061127  0.035326 -0.035388 -0.090728 -0.018634   \n",
       "3      male -0.103057  0.085044  0.078333 -0.035873 -0.028163  0.004924   \n",
       "4      male -0.125815  0.120046  0.023131 -0.042901  0.038215 -0.049677   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "795  female -0.164731  0.064301  0.058630 -0.017420 -0.157600 -0.022536   \n",
       "796  female -0.095308  0.051095  0.092913 -0.101745 -0.083153 -0.028159   \n",
       "797  female -0.202852  0.037039  0.079731 -0.047156 -0.140062 -0.080246   \n",
       "798  female -0.088300  0.063530  0.049627 -0.026011 -0.172773  0.086218   \n",
       "799  female -0.156201  0.055165  0.142716 -0.115393 -0.128982 -0.139830   \n",
       "\n",
       "            6         7         8  ...       118       119       120  \\\n",
       "0   -0.002637 -0.158467  0.130467  ...  0.025989 -0.001087  0.027260   \n",
       "1   -0.019530 -0.119905  0.186553  ...  0.044229 -0.023900 -0.028108   \n",
       "2   -0.024315 -0.139786  0.052211  ...  0.111141  0.059436 -0.029222   \n",
       "3    0.007829 -0.017016  0.114907  ...  0.100793 -0.002644 -0.023388   \n",
       "4   -0.054258 -0.130758  0.173457  ...  0.090197  0.067527  0.039926   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795  0.002864 -0.072739  0.030554  ...  0.095115  0.007198 -0.004655   \n",
       "796  0.009090 -0.114513  0.157421  ...  0.056078  0.119846  0.087470   \n",
       "797  0.057668 -0.122083  0.165443  ...  0.066954  0.035684 -0.023112   \n",
       "798  0.042710 -0.161852  0.185083  ...  0.039460  0.067547  0.040426   \n",
       "799 -0.037305 -0.101402  0.048473  ...  0.024955  0.066980 -0.002332   \n",
       "\n",
       "          121       122       123       124       125       126       127  \n",
       "0   -0.046754 -0.118619 -0.163774 -0.000590 -0.076400  0.107497  0.001567  \n",
       "1    0.040618 -0.146579 -0.141244  0.016162  0.017638  0.080610 -0.015930  \n",
       "2    0.042115 -0.222173 -0.116908  0.093428  0.017391  0.057652  0.086116  \n",
       "3    0.029497 -0.139830 -0.119243  0.005306 -0.015100  0.161575  0.062462  \n",
       "4    0.047469 -0.056852 -0.076700  0.004966  0.028171  0.026041  0.084135  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "795  0.023957 -0.170753 -0.136630  0.041614  0.031600  0.019064  0.004384  \n",
       "796  0.017481 -0.096594 -0.084553  0.037709  0.030732 -0.083713  0.064970  \n",
       "797 -0.030452 -0.154243 -0.188270  0.071086  0.037384 -0.006257  0.039977  \n",
       "798  0.028007 -0.154515 -0.127736  0.046967  0.009701 -0.016942  0.048071  \n",
       "799 -0.045738 -0.110557 -0.014995 -0.002124 -0.010298 -0.028856  0.075323  \n",
       "\n",
       "[800 rows x 129 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset):\n",
    "    classes = dataset['class'].unique()\n",
    "    test, train = pd.DataFrame(), pd.DataFrame()\n",
    "    for c in classes:\n",
    "        class_data = dataset[dataset['class'] == c]\n",
    "        test = pd.concat([test, class_data.iloc[:10]], ignore_index=True)\n",
    "        train = pd.concat([train, class_data.iloc[10:]], ignore_index=True)\n",
    "    X_train, X_test = train.iloc[:, 1:].values, test.iloc[:, 1:].values\n",
    "    y_train, y_test = train.iloc[:, 0].values, test.iloc[:, 0].values\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA():\n",
    "    def __init__(self, n_components = 2):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, train: pd.DataFrame, test: pd.DataFrame):\n",
    "        classes = test['class'].unique()\n",
    "        self.wc_scatter_matrices = []\n",
    "        self.mean_vectors = []\n",
    "\n",
    "        for c in classes:\n",
    "            class_data_set = train[test['class'] == c]\n",
    "            self.mean_vectors.append(mean_vector(class_data_set))\n",
    "        \n",
    "        for i in range(len(classes)):\n",
    "            si = np.zeros((len(classes), len(classes)))\n",
    "            for j in range(len(classes[i])):\n",
    "                required_vector = classes[i][j] - self.mean_vectors[i]\n",
    "                si += np.dot(required_vector, required_vector.T)\n",
    "            self.wc_scatter_matrices.append(si)\n",
    "        \n",
    "        self.sw = np.zeros((len(classes), len(classes)))\n",
    "        for i in range(len(classes)):\n",
    "            self.sw += self.wc_scatter_matrices[i]\n",
    "\n",
    "        self.sb = np.zeros((len(classes), len(classes)))\n",
    "        for i in range(len(classes)):\n",
    "            mean_vector = mean_vector(train)\n",
    "            required_vector = self.mean_vectors[i] - mean_vector\n",
    "            self.sb += np.dot(required_vector, required_vector.T)\n",
    "            \n",
    "        self.linear_discriminants = np.dot(np.linalg.inv(self.sw), self.sb)\n",
    "        self.eigen_values, self.eigen_vectors = np.linalg.eig(self.linear_discriminants)\n",
    "\n",
    "        self.eig_pairs = [(np.abs(self.eigen_values[i]), self.eigen_vectors[:,i]) for i in range(len(self.eigen_values))]\n",
    "        self.eig_pairs = sorted(self.eig_pairs, key=lambda k: k[0], reverse=True)\n",
    "\n",
    "        self.selected_eigen_vectors = []\n",
    "        for i in range(self.n_components):\n",
    "            self.selected_eigen_vectors.append(self.eig_pairs[i][1].reshape(len(classes),1))\n",
    "        \n",
    "        self.final_matrix = np.hstack(self.selected_eigen_vectors)\n",
    "    \n",
    "    def transform(self, train: pd.DataFrame, test: pd.DataFrame):\n",
    "        return np.dot(train, self.final_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    \n",
    "    def knn(self, test_point):\n",
    "        distances = []\n",
    "        for i in range(self.X_train.shape[0]):\n",
    "            train_point = self.X_train[i, :]\n",
    "            dist = euclidean_distance(test_point, train_point)\n",
    "            distances.append((dist, self.y_train[i]))\n",
    "        distances.sort()\n",
    "        return distances[:self.k]\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for i in range(X_test.shape[0]):\n",
    "            test_point = X_test[i, :]\n",
    "            k_nearest_neighbours = self.knn(test_point)\n",
    "            nearest_labels = pd.DataFrame([label for _,label in k_nearest_neighbours])\n",
    "            y_pred.append(nearest_labels.mode()[0][0])\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/siddesh/Desktop/Programming/PRML/lab-09/CS21B2019_Q1.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddesh/Desktop/Programming/PRML/lab-09/CS21B2019_Q1.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lda \u001b[39m=\u001b[39m LDA(n_components\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/siddesh/Desktop/Programming/PRML/lab-09/CS21B2019_Q1.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lda\u001b[39m.\u001b[39mfit(X_train, X_test)\n",
      "\u001b[1;32m/Users/siddesh/Desktop/Programming/PRML/lab-09/CS21B2019_Q1.ipynb Cell 18\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddesh/Desktop/Programming/PRML/lab-09/CS21B2019_Q1.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, train: pd\u001b[39m.\u001b[39mDataFrame, test: pd\u001b[39m.\u001b[39mDataFrame):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/siddesh/Desktop/Programming/PRML/lab-09/CS21B2019_Q1.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     classes \u001b[39m=\u001b[39m test[\u001b[39m'\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddesh/Desktop/Programming/PRML/lab-09/CS21B2019_Q1.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwc_scatter_matrices \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/siddesh/Desktop/Programming/PRML/lab-09/CS21B2019_Q1.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_vectors \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "lda = LDA(n_components=20)\n",
    "lda.fit(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
