# -*- coding: utf-8 -*-
"""4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/DSLRSIDDESH/Pattern-Recognition-and-ML/blob/main/lab-07/4.ipynb

### Import Libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""### Load Data"""

iris_data = pd.read_csv('iris.csv').drop('Id', axis=1)
iris_data

"""### Train Test Split"""

def train_test_split(data, class_column, train_size = 40):
    classes = data[class_column].unique()
    test, train = pd.DataFrame(), pd.DataFrame()
    for c in classes:
        currentClass = data[data[class_column] == c]
        test = pd.concat([test, currentClass.iloc[train_size:, :]], ignore_index=True)
        train = pd.concat([train, currentClass.iloc[:train_size, :]], ignore_index=True)
    train_X, train_y = train.iloc[:, :-1], train.iloc[:, -1]
    test_X, test_y = test.iloc[:, :-1], test.iloc[:, -1]
    return train_X, train_y, test_X, test_y

train_X, train_y, test_X, test_y = train_test_split(iris_data, 'Species', 40)

"""### Bayes Classifier"""

#function to find covariance matrix
def covariance_matrix(data):
    mean_vector = np.mean(data, axis=0)
    z_matrix = data - mean_vector
    cov_matrix = np.dot(z_matrix.T, z_matrix) / (data.shape[0] - 1)
    return cov_matrix

def fit_bayes_classifier(train_X, train_y):
    classes = np.unique(train_y)
    cov_mats, cov_dets = {}, {}
    inv_cov_mats = {}
    mean_vectors = {}
    apriori = {}
    for c in classes:
        apriori[c] = len(train_y[train_y == c]) / len(train_y)
        mean_vectors[c] = np.array(train_X[train_y == c].mean())
        cov_mats[c] = covariance_matrix(np.array(train_X[train_y == c]))
        cov_dets[c] = np.linalg.det(cov_mats[c])
        inv_cov_mats[c] = np.linalg.inv(cov_mats[c])
    return cov_dets, inv_cov_mats, apriori, mean_vectors

def predict(apriori, mean_vectors, cov_dets, inv_cov_mats, train_X, train_y, test_point):
    classes = np.unique(train_y)
    dimensions = train_X.shape[1]
    class_probabilities = {}

    for c in classes:
        req_vector = np.array(test_point) - mean_vectors[c]
        numerator = np.exp(-0.5 * np.dot(np.dot(req_vector.T, inv_cov_mats[c]), req_vector))
        denominator = np.power(2 * np.pi, dimensions / 2) * np.power(cov_dets[c], 0.5)
        class_probabilities[c] = apriori[c] * (numerator / denominator)

    cl = max(zip(class_probabilities.values(), class_probabilities.keys()))[1]
    for i in range(len(classes)):
        if classes[i] == cl:
            return i

def discriminant_function(apriori, mean_vectors, cov_dets, inv_cov_mats, train_X, train_y, test_point):
    classes = np.unique(train_y)
    dimensions = train_X.shape[1]
    class_probabilities = {}

    for c in classes:
        req_vector = np.array(test_point) - mean_vectors[c]
        numerator = np.exp(-0.5 * np.dot(np.dot(req_vector.T, inv_cov_mats[c]), req_vector))
        denominator = np.power(2 * np.pi, dimensions / 2) * np.power(cov_dets[c], 0.5)
        class_probabilities[c] = apriori[c] * (numerator / denominator)

    return max(class_probabilities.values())

cov_dets, inv_cov_mats, aprioris, mean_vectors = fit_bayes_classifier(train_X.iloc[:, 2:], train_y)

"""### Plotting"""

x_min, x_max = train_X.iloc[:, 2].min() - 1, train_X.iloc[:, 2].max() + 1
y_min, y_max = train_X.iloc[:, 3].min() - 1, train_X.iloc[:, 3].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))
z = []
for i in range(xx.shape[0]):
    for j in range(yy.shape[1]):
        z.append(predict(aprioris, mean_vectors, cov_dets, inv_cov_mats, train_X.iloc[:, 2:], train_y, [xx[i][j], yy[i][j]]))
z = np.array(z)
Z = z.reshape(xx.shape)

plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha = 0.9)
train_yy = np.zeros_like(train_y)
classes = np.unique(train_y)
for i in range(len(classes)):
    train_yy[train_y == classes[i]] = i
plt.scatter(train_X.iloc[:, 2], train_X.iloc[:, 3], c = train_yy, cmap = plt.cm.RdBu, edgecolor='k')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Naive Bayes Decision Boundaries')
plt.show()

x_min, x_max = train_X.iloc[:, 2].min() - 1, train_X.iloc[:, 2].max() + 1
y_min, y_max = train_X.iloc[:, 3].min() - 1, train_X.iloc[:, 3].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))
z1 = []
for i in range(xx.shape[0]):
    for j in range(yy.shape[1]):
        z1.append(discriminant_function(aprioris, mean_vectors, cov_dets, inv_cov_mats, train_X.iloc[:, 2:], train_y, [xx[i][j], yy[i][j]]))
z1 = np.array(z1)
Z1 = z1.reshape(xx.shape)

plt.contourf(xx, yy, Z1, cmap=plt.cm.RdBu, alpha = 0.9)
train_yy = np.zeros_like(train_y)
classes = np.unique(train_y)
for i in range(len(classes)):
    train_yy[train_y == classes[i]] = i
plt.scatter(train_X.iloc[:, 2], train_X.iloc[:, 3], c = train_yy, cmap = plt.cm.RdBu, edgecolor='k')
plt.xlabel('Feature 1')
plt.ylabel('Feature 2')
plt.title('Discriminant Function values')
plt.show()